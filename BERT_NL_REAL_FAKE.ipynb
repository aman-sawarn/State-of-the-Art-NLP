{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M3J57-CfR33N"
   },
   "outputs": [],
   "source": [
    "def plt_dynamic(x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "znxh-i2XR5U2",
    "outputId": "91b0e382-c7bc-47e5-8990-dd7e772a6965"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "62kzQIOvR8RU",
    "outputId": "a0faa06c-3bf5-48a5-bfb2-75da9b2f16ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert-tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
      "\r",
      "\u001b[K     |████▉                           | 10kB 28.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 20kB 31.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 30kB 37.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 40kB 41.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 51kB 24.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 61kB 26.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 9.4MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
      "Installing collected packages: bert-tensorflow\n",
      "Successfully installed bert-tensorflow-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bert-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "colab_type": "code",
    "id": "u4pO19FESOHv",
    "outputId": "5e7b3029-e3f8-410e-d5b3-47ac06bc3cc4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LCPbKPVZSOKj",
    "outputId": "8706d7bc-04af-42a6-a3f3-e34fbb9b64d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Layer\n",
    "\n",
    "class BertLayer(Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_path,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ-8tTxWSONe"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length): \n",
    "    in_id = Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
    "    dense = Dense(256, activation='relu')(bert_output)\n",
    "    pred = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SYB2Hl3PSOQG"
   },
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "colab_type": "code",
    "id": "YTJHkyHjSOTR",
    "outputId": "f66b590f-efb7-4f90-b638-0a381bbcf6ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = create_tokenizer_from_hub_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "je7kvxwNSnrd"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from bert.tokenization import FullTokenizer\n",
    "from tqdm import tqdm_notebook\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Params for bert model and tokenization\n",
    "bert_path = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
    "max_seq_length = 160"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJqf1E2hSnxL"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Layer\n",
    "\n",
    "class BertLayer(Layer):\n",
    "    def __init__(self, n_fine_tune_layers=10, **kwargs):\n",
    "        self.n_fine_tune_layers = n_fine_tune_layers\n",
    "        self.trainable = True\n",
    "        self.output_size = 768\n",
    "        super(BertLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.bert = hub.Module(\n",
    "            bert_path,\n",
    "            trainable=self.trainable,\n",
    "            name=\"{}_module\".format(self.name)\n",
    "        )\n",
    "        trainable_vars = self.bert.variables\n",
    "        \n",
    "        # Remove unused layers\n",
    "        trainable_vars = [var for var in trainable_vars if not \"/cls/\" in var.name]\n",
    "        \n",
    "        # Select how many layers to fine tune\n",
    "        trainable_vars = trainable_vars[-self.n_fine_tune_layers :]\n",
    "        \n",
    "        # Add to trainable weights\n",
    "        for var in trainable_vars:\n",
    "            self._trainable_weights.append(var)\n",
    "        \n",
    "        # Add non-trainable weights\n",
    "        for var in self.bert.variables:\n",
    "            if var not in self._trainable_weights:\n",
    "                self._non_trainable_weights.append(var)\n",
    "        \n",
    "        super(BertLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        inputs = [K.cast(x, dtype=\"int32\") for x in inputs]\n",
    "        input_ids, input_mask, segment_ids = inputs\n",
    "        bert_inputs = dict(\n",
    "            input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids\n",
    "        )\n",
    "        result = self.bert(inputs=bert_inputs, signature=\"tokens\", as_dict=True)[\n",
    "            \"pooled_output\"\n",
    "        ]\n",
    "        return result\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "onwxQzx6Sn0F"
   },
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(max_seq_length): \n",
    "    in_id = Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "    in_mask = Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "    in_segment = Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "    bert_inputs = [in_id, in_mask, in_segment]\n",
    "    \n",
    "    bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
    "    dense = Dense(256, activation='relu')(bert_output)\n",
    "    pred = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "    model = Model(inputs=bert_inputs, outputs=pred)\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def initialize_vars(sess):\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    K.set_session(sess)\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Da3IzwiLSn3S"
   },
   "outputs": [],
   "source": [
    "class PaddingInputExample(object):\n",
    "    \"\"\"Fake example so the num input examples is a multiple of the batch size.\n",
    "  When running eval/predict on the TPU, we need to pad the number of examples\n",
    "  to be a multiple of the batch size, because the TPU requires a fixed batch\n",
    "  size. The alternative is to drop the last batch, which is bad because it means\n",
    "  the entire output data won't be generated.\n",
    "  We use this class instead of `None` because treating `None` as padding\n",
    "  battches could cause silent errors.\n",
    "  \"\"\"\n",
    "\n",
    "class InputExample(object):\n",
    "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "        \"\"\"Constructs a InputExample.\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "        self.guid = guid\n",
    "        self.text_a = text_a\n",
    "        self.text_b = text_b\n",
    "        self.label = label\n",
    "\n",
    "def create_tokenizer_from_hub_module():\n",
    "    \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
    "    bert_module =  hub.Module(bert_path)\n",
    "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
    "    vocab_file, do_lower_case = sess.run(\n",
    "        [\n",
    "            tokenization_info[\"vocab_file\"],\n",
    "            tokenization_info[\"do_lower_case\"],\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return FullTokenizer(vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
    "\n",
    "def convert_single_example(tokenizer, example, max_seq_length=256):\n",
    "    \"\"\"Converts a single `InputExample` into a single `InputFeatures`.\"\"\"\n",
    "\n",
    "    if isinstance(example, PaddingInputExample):\n",
    "        input_ids = [0] * max_seq_length\n",
    "        input_mask = [0] * max_seq_length\n",
    "        segment_ids = [0] * max_seq_length\n",
    "        label = 0\n",
    "        return input_ids, input_mask, segment_ids, label\n",
    "\n",
    "    tokens_a = tokenizer.tokenize(example.text_a)\n",
    "    if len(tokens_a) > max_seq_length - 2:\n",
    "        tokens_a = tokens_a[0 : (max_seq_length - 2)]\n",
    "\n",
    "    tokens = []\n",
    "    segment_ids = []\n",
    "    tokens.append(\"[CLS]\")\n",
    "    segment_ids.append(0)\n",
    "    for token in tokens_a:\n",
    "        tokens.append(token)\n",
    "        segment_ids.append(0)\n",
    "    tokens.append(\"[SEP]\")\n",
    "    segment_ids.append(0)\n",
    "\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "    # tokens are attended to.\n",
    "    input_mask = [1] * len(input_ids)\n",
    "\n",
    "    # Zero-pad up to the sequence length.\n",
    "    while len(input_ids) < max_seq_length:\n",
    "        input_ids.append(0)\n",
    "        input_mask.append(0)\n",
    "        segment_ids.append(0)\n",
    "\n",
    "    assert len(input_ids) == max_seq_length\n",
    "    assert len(input_mask) == max_seq_length\n",
    "    assert len(segment_ids) == max_seq_length\n",
    "\n",
    "    return input_ids, input_mask, segment_ids, example.label\n",
    "\n",
    "def convert_examples_to_features(tokenizer, examples, max_seq_length=256):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids, labels = [], [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        labels.append(label)\n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "        np.array(labels).reshape(-1, 1),\n",
    "    )\n",
    "\n",
    "def convert_text_to_examples(texts, labels):\n",
    "    \"\"\"Create InputExamples\"\"\"\n",
    "    InputExamples = []\n",
    "    for text, label in zip(texts, labels):\n",
    "        InputExamples.append(\n",
    "            InputExample(guid=None, text_a=\" \".join(text), text_b=None, label=label)\n",
    "        )\n",
    "    return InputExamples\n",
    "\n",
    "def convert_text_to_examples_test(texts):\n",
    "    InputExamples = []\n",
    "    for text in texts:\n",
    "        InputExamples.append(InputExample(guid=None, text_a=\" \".join(text), text_b=None))\n",
    "    return InputExamples\n",
    "def convert_examples_to_features_test(tokenizer, examples, max_seq_length=160):\n",
    "    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n",
    "\n",
    "    input_ids, input_masks, segment_ids = [], [], []\n",
    "    for example in tqdm_notebook(examples, desc=\"Converting examples to features\"):\n",
    "        input_id, input_mask, segment_id, label = convert_single_example(\n",
    "            tokenizer, example, max_seq_length\n",
    "        )\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "        \n",
    "    return (\n",
    "        np.array(input_ids),\n",
    "        np.array(input_masks),\n",
    "        np.array(segment_ids),\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8bGcLKQbSnu9"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Real or Fake/train.csv\")\n",
    "test_df = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Real or Fake/test.csv\")\n",
    "original=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/NLP Real or Fake/NLP Original.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "7CWKQ8gBZJYR",
    "outputId": "8180a321-1d69-460e-d7e9-230871a5a9d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer\n",
    "tokenizer = convert_examples_to_features_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Pf7qWllZoWn"
   },
   "outputs": [],
   "source": [
    "train_text, test_text, train_label, test_label = train_test_split( train_df['text'], train_df['target'], test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115,
     "referenced_widgets": [
      "4bca52bdc0494fdeb03b885fa5886340",
      "e4419efd9e394edb8e36f510b5ee6063",
      "3c6c8ec590d540d9bb9b7db4014f9441",
      "07a046f43c8445b6ad8a6bd5aab80234",
      "6ba323d91143449da73286d9db14f029",
      "dbf6bd4061644d7e9b7c92930f8817d9",
      "a882d8dd075047bc9d213cbd5f79a761",
      "8274fb7f250749778689b8d2d751eed8",
      "b938b9f4f7674e628baa8348dd1bb5ab",
      "66a20fdc61764b959d3e093a6a78cf29",
      "46b4849c4cfd4084876392b9122e1c8f",
      "cd7b405737df42c2a3936f785a7c2147",
      "bcf122dcc5494cb0bfcfc7392c64e469",
      "7f437541ae70457b95773509944be4b2",
      "cc01e29f173b4afdb4eb43df22bb3f62",
      "f7e0f244f0da4857866a6edb47ea5b4e"
     ]
    },
    "colab_type": "code",
    "id": "eyzJ6jLhZrzI",
    "outputId": "9e3263b4-f6f4-4ac4-c469-767456a88c8e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bca52bdc0494fdeb03b885fa5886340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=6090, style=ProgressSty…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b938b9f4f7674e628baa8348dd1bb5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=1523, style=ProgressSty…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert data to InputExample format\n",
    "train_examples = convert_text_to_examples(train_text, train_label)\n",
    "test_examples = convert_text_to_examples(test_text, test_label)\n",
    "\n",
    "# Convert to features\n",
    "(train_input_ids, train_input_masks, train_segment_ids, train_labels\n",
    " ) = convert_examples_to_features(tokenizer, train_examples, max_seq_length=max_seq_length)\n",
    "(test_input_ids, test_input_masks, test_segment_ids, test_labels\n",
    ") = convert_examples_to_features(tokenizer, test_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "aaa7e839bac540bb9c3a5a629aebf3de",
      "2f32826e5d5547ddbd597f039eb16e1d",
      "9e998d6cf58a4b89b9bf2b96dc43afa2",
      "c88b6b2a3e2d47418692b684a5975126",
      "6203a6f36a804a6997841c02a1cea186",
      "3b52b69f323f460585e8b963dd93b80a",
      "e7d0729a7edd4137bb9921b13b398054",
      "b5b90bc635aa4e67ab289b6b8036bb57"
     ]
    },
    "colab_type": "code",
    "id": "9-Ee8JgCyfz4",
    "outputId": "0e9ac043-0c9d-45ba-aa5b-c4266154c042"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa7e839bac540bb9c3a5a629aebf3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=3263, style=ProgressSty…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_submission_examples=convert_text_to_examples_test(test_df['text'])\n",
    "(test_input_ids_submisson, test_input_masks_submisson, test_segment_ids_submisson\n",
    ") = convert_examples_to_features_test(tokenizer, test_submission_examples, max_seq_length=max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "9cdeqfmOZuG-",
    "outputId": "d0a82a86-57bd-46bf-d609-7862f266818a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_3 (BertLayer)        ((None, 160), 768)   110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 ((None, 160), 256)   196864      bert_layer_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 ((None, 160), 1)     257         dense_5[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 3,147,009\n",
      "Non-trainable params: 107,155,002\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "in_id = Input(shape=(max_seq_length,), name=\"input_ids\")\n",
    "in_mask = Input(shape=(max_seq_length,), name=\"input_masks\")\n",
    "in_segment = Input(shape=(max_seq_length,), name=\"segment_ids\")\n",
    "bert_inputs = [in_id, in_mask, in_segment]\n",
    "bert_output = BertLayer(n_fine_tune_layers=3)(bert_inputs)\n",
    "dense = Dense(256, activation='relu')(bert_output)\n",
    "pred = Dense(1, activation='sigmoid')(dense)\n",
    "    \n",
    "model = Model(inputs=bert_inputs, outputs=pred)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "colab_type": "code",
    "id": "aizzvqpCb_nq",
    "outputId": "fa8183fe-19e6-4994-fc80-6cf7d973fe8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6090 samples, validate on 1523 samples\n",
      "Epoch 1/5\n",
      "6090/6090 [==============================] - 113s 19ms/step - loss: 0.7187 - acc: 0.5995 - val_loss: 0.6304 - val_acc: 0.6395\n",
      "Epoch 2/5\n",
      "6090/6090 [==============================] - 104s 17ms/step - loss: 0.6300 - acc: 0.6443 - val_loss: 0.6057 - val_acc: 0.6763\n",
      "Epoch 3/5\n",
      "6090/6090 [==============================] - 104s 17ms/step - loss: 0.6216 - acc: 0.6542 - val_loss: 0.6033 - val_acc: 0.6756\n",
      "Epoch 4/5\n",
      "6090/6090 [==============================] - 104s 17ms/step - loss: 0.6013 - acc: 0.6862 - val_loss: 0.5864 - val_acc: 0.6940\n",
      "Epoch 5/5\n",
      "6090/6090 [==============================] - 104s 17ms/step - loss: 0.5854 - acc: 0.6957 - val_loss: 0.5925 - val_acc: 0.6940\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=5,\n",
    "    batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "aQgdW2wWcJt2",
    "outputId": "8275f3e3-fd85-46e9-fff6-167dbdf7cb53"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2XMZR/IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "x = list(range(1,6))\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "id": "Pgp1bWn5rqyh",
    "outputId": "a27a0a21-d77e-4e74-a76b-2d0b7feea52d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6090 samples, validate on 1523 samples\n",
      "Epoch 1/5\n",
      "2176/6090 [=========>....................] - ETA: 54s - loss: 0.3994 - acc: 0.8263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-2f0476433127>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_input_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_input_masks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_segment_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     batch_size=128 )\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history=model.fit(\n",
    "    [train_input_ids, train_input_masks, train_segment_ids], \n",
    "    train_labels,\n",
    "    validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "    epochs=5,\n",
    "    batch_size=128 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "McOll9B9rq_W"
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "x = list(range(1,6))\n",
    "\n",
    "vy = history.history['val_loss']\n",
    "ty = history.history['loss']\n",
    "plt_dynamic(x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "id": "cKvw6t0daHLy",
    "outputId": "45f2c6f4-7db6-4a0d-edb7-682568585242"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_masks (InputLayer)        (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "segment_ids (InputLayer)        (None, 160)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bert_layer_2 (BertLayer)        ((None, 160), 768)   110104890   input_ids[0][0]                  \n",
      "                                                                 input_masks[0][0]                \n",
      "                                                                 segment_ids[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 ((None, 160), 256)   196864      bert_layer_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 ((None, 160), 1)     257         dense_3[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 110,302,011\n",
      "Trainable params: 3,147,009\n",
      "Non-trainable params: 107,155,002\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-95c5d31dd9c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Instantiate variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minitialize_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m model.fit(\n",
      "\u001b[0;32m<ipython-input-12-cbdfeebba7d9>\u001b[0m in \u001b[0;36minitialize_vars\u001b[0;34m(sess)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minitialize_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# model = build_model(max_seq_length)\n",
    "\n",
    "# # Instantiate variables\n",
    "# initialize_vars(sess)\n",
    "\n",
    "# model.fit(\n",
    "#     [train_input_ids, train_input_masks, train_segment_ids], \n",
    "#     train_labels,\n",
    "#     validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\n",
    "#     epochs=1,\n",
    "#     batch_size=32 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R6c5VJK4azR5"
   },
   "outputs": [],
   "source": [
    "pred=model.predict([test_input_ids_submisson, test_input_masks_submisson, test_segment_ids_submisson])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "5e2nZHE1y5PO",
    "outputId": "3e6d3771-e3fc-4494-a3a3-80e6090de5c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.661422484431334"
      ]
     },
     "execution_count": 53,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(original['target'], pred.round())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "o2O2MXB2zLBi",
    "outputId": "f04f8739-4ce4-4367-b0ce-7f4b2eba6755"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1861\n",
       "1    1402\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "bgVKxbrxzubN",
    "outputId": "be5d9266-f7d2-4e39-f2e2-4197a81b9986"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-4537f45a42c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submission.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'to_csv'"
     ]
    }
   ],
   "source": [
    "pred.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QT4AC367388a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "BERT NL REAL FAKE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07a046f43c8445b6ad8a6bd5aab80234": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8274fb7f250749778689b8d2d751eed8",
      "placeholder": "​",
      "style": "IPY_MODEL_a882d8dd075047bc9d213cbd5f79a761",
      "value": "100% 6090/6090 [00:03&lt;00:00, 1653.90it/s]"
     }
    },
    "2f32826e5d5547ddbd597f039eb16e1d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b52b69f323f460585e8b963dd93b80a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c6c8ec590d540d9bb9b7db4014f9441": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbf6bd4061644d7e9b7c92930f8817d9",
      "max": 6090,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6ba323d91143449da73286d9db14f029",
      "value": 6090
     }
    },
    "46b4849c4cfd4084876392b9122e1c8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f437541ae70457b95773509944be4b2",
      "max": 1523,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bcf122dcc5494cb0bfcfc7392c64e469",
      "value": 1523
     }
    },
    "4bca52bdc0494fdeb03b885fa5886340": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3c6c8ec590d540d9bb9b7db4014f9441",
       "IPY_MODEL_07a046f43c8445b6ad8a6bd5aab80234"
      ],
      "layout": "IPY_MODEL_e4419efd9e394edb8e36f510b5ee6063"
     }
    },
    "6203a6f36a804a6997841c02a1cea186": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "66a20fdc61764b959d3e093a6a78cf29": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6ba323d91143449da73286d9db14f029": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "7f437541ae70457b95773509944be4b2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8274fb7f250749778689b8d2d751eed8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9e998d6cf58a4b89b9bf2b96dc43afa2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Converting examples to features",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3b52b69f323f460585e8b963dd93b80a",
      "max": 3263,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6203a6f36a804a6997841c02a1cea186",
      "value": 3263
     }
    },
    "a882d8dd075047bc9d213cbd5f79a761": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "aaa7e839bac540bb9c3a5a629aebf3de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9e998d6cf58a4b89b9bf2b96dc43afa2",
       "IPY_MODEL_c88b6b2a3e2d47418692b684a5975126"
      ],
      "layout": "IPY_MODEL_2f32826e5d5547ddbd597f039eb16e1d"
     }
    },
    "b5b90bc635aa4e67ab289b6b8036bb57": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b938b9f4f7674e628baa8348dd1bb5ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_46b4849c4cfd4084876392b9122e1c8f",
       "IPY_MODEL_cd7b405737df42c2a3936f785a7c2147"
      ],
      "layout": "IPY_MODEL_66a20fdc61764b959d3e093a6a78cf29"
     }
    },
    "bcf122dcc5494cb0bfcfc7392c64e469": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c88b6b2a3e2d47418692b684a5975126": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5b90bc635aa4e67ab289b6b8036bb57",
      "placeholder": "​",
      "style": "IPY_MODEL_e7d0729a7edd4137bb9921b13b398054",
      "value": "100% 3263/3263 [00:02&lt;00:00, 1400.40it/s]"
     }
    },
    "cc01e29f173b4afdb4eb43df22bb3f62": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cd7b405737df42c2a3936f785a7c2147": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7e0f244f0da4857866a6edb47ea5b4e",
      "placeholder": "​",
      "style": "IPY_MODEL_cc01e29f173b4afdb4eb43df22bb3f62",
      "value": "100% 1523/1523 [00:00&lt;00:00, 1612.03it/s]"
     }
    },
    "dbf6bd4061644d7e9b7c92930f8817d9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4419efd9e394edb8e36f510b5ee6063": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7d0729a7edd4137bb9921b13b398054": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7e0f244f0da4857866a6edb47ea5b4e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
